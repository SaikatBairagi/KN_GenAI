{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da286665",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067eb094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17cc170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openAIKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openAIKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a2632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(os.environ[\"LANGCHAIN_PROJECT\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7867be69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x10dcc3800> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10dd8d280> root_client=<openai.OpenAI object at 0x10d2b50d0> root_async_client=<openai.AsyncOpenAI object at 0x10dbafd10> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a941ac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentinc AI appears to be a real estate platform designed to improve the process of buying and selling homes by using artificial intelligence. It aims to provide more accurate property valuations, streamline real estate transactions, and enhance the overall customer experience. By leveraging AI, Agentinc AI could offer features such as data-driven insights on market trends, personalized property recommendations, and improved efficiency in handling real estate transactions. However, specific details about Agentinc AI could vary, and it's advisable to refer to their official website or contact them directly for the most current and detailed information.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is Agentinc AI?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea18dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an helpful assistant\"),\n",
    "        (\"user\",\"{input}\" )\n",
    "    ]\n",
    ")\n",
    "print(prompt.input_variables)\n",
    "print(prompt.output_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc116f",
   "metadata": {},
   "source": [
    "## Langchain pipeing prompt with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d560e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to simplify the development of applications utilizing language models. It focuses on handling common challenges and tasks associated with working in this area. The framework can be used for several key use cases:\n",
      "\n",
      "1. **Agents**: LangChain helps in building agents that can perform a variety of actions based on input prompts. These agents have the capability to execute tasks or retrieve information from different sources dynamically.\n",
      "\n",
      "2. **Chains**: Chains are sequences of calls to language models or other tasks. LangChain allows developers to construct these chains to manage complex workflows, where outputs from one model can be inputs to another, or combined with external data sources.\n",
      "\n",
      "3. **Data Augmented Generation**: This involves enhancing the performance of language models by providing them access to external data. LangChain provides tools to integrate language models with databases, search engines, APIs, and other data sources.\n",
      "\n",
      "4. **Memory**: LangChain includes features that allow language models to maintain state or context over a session or between interactions, which is useful for personalized or contextual responses.\n",
      "\n",
      "LangChain supports multiple programming languages and is designed to work with a variety of different language models, enhancing their utility and facilitating their integration into more complex applications. It is particularly useful for building conversational AI, question-answering systems, and customized natural language processing solutions.\n"
     ]
    }
   ],
   "source": [
    "response = prompt | llm\n",
    "output=response.invoke({\"input\":\"What is Langchain?\"})\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d593963",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83c0c435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of New Jersey is Trenton.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"What is a capital of NJ?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72f3a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You are an Helpful AI assistant, Based on the user {query} response in {format_template}\",\n",
    "    input_variables = [\"query\"],\n",
    "    partial_variables={\"format_template\":parser.get_format_instructions()}\n",
    "    )\n",
    "prompt\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\"query\":\"What is a capital of NJ?\"})\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416a035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
